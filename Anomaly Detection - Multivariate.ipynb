{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# feature = [\"cpu\",\"file\",\"memory\",\"network\"]\n",
    "\n",
    "numOfData = 10075;\n",
    "\n",
    "def initData():\n",
    "  \n",
    "    filename_queue = tf.train.string_input_producer([\"anomaly - Normalization.csv\"])\n",
    "    reader = tf.TextLineReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "    record_defaults = [[1.],[1.],[1.],[1.],[\"s\"]]\n",
    "    cpu,file,memory,network,time = tf.decode_csv(\n",
    "        value, record_defaults=record_defaults)\n",
    "    features = tf.stack([cpu,file,memory,network])\n",
    "    dataSet = [[0 for col in range(1)] for row in range(5)]\n",
    "    with tf.Session() as sess:\n",
    "      # Start populating the filename queue.\n",
    "      coord = tf.train.Coordinator()\n",
    "      threads = tf.train.start_queue_runners(coord=coord)\n",
    "      for i in range(numOfData):\n",
    "        # Retrieve a single instance:\n",
    "        data1,data2,data3,data4= sess.run(features)\n",
    "        dataSet[0].insert(i,data1)\n",
    "        dataSet[1].insert(i,data2)\n",
    "        dataSet[2].insert(i,data3)\n",
    "        dataSet[3].insert(i,data4)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    print(\"initData done\")\n",
    "    return dataSet\n",
    "\n",
    "\n",
    "def initDist(dataSet):\n",
    "    \n",
    "    cpuData = np.array(dataSet[0])\n",
    "    \n",
    "    fileData = np.array(dataSet[1])\n",
    "\n",
    "    memoryData = np.array(dataSet[2])\n",
    "\n",
    "    networkData = np.array(dataSet[3])\n",
    "\n",
    "    data= np.vstack((cpuData,fileData,memoryData,networkData))\n",
    "\n",
    "    mu = np.mean(data,axis=1,dtype =np.float32)\n",
    "    print(\"means\")\n",
    "    print(mu)\n",
    "    \n",
    "    cor = np.corrcoef(data)\n",
    "    print(\"correlation\")\n",
    "    print(cor)\n",
    "    \n",
    "    chol = (np.cov(data,bias=True))\n",
    "    print(\"cov\")\n",
    "    print(chol)\n",
    "    \n",
    "    dist = multivariate_normal(mean=mu, cov=chol)\n",
    "    #dist =  tf.contrib.distributions.MultivariateNormalFull(mu, chol)\n",
    "    print(\"initDist\")\n",
    "    return dist\n",
    "\n",
    "def getDataSample(dataSet,i):\n",
    "    dataSample = []\n",
    "    dataSample.append(dataSet[0][i])\n",
    "    dataSample.append(dataSet[1][i])\n",
    "    dataSample.append(dataSet[2][i])\n",
    "    dataSample.append(dataSet[3][i])\n",
    "    return dataSample\n",
    "\n",
    "def getPdf(dist,data):\n",
    "    return dist.pdf(data)\n",
    "\n",
    "def getPdfProductSet(dist,dataSet):\n",
    "    pdfProductSet = []\n",
    "    for i in range(numOfData):\n",
    "        pdf = getPdf(dist,getDataSample(dataSet,i))\n",
    "        pdfProductSet.append(pdf)\n",
    "    return pdfProductSet    \n",
    "\n",
    "def getMinPdf(pdfProductSet):\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "\n",
    "    pdfProductData = np.array(pdfProductSet)\n",
    "    pdfProductMin = tf.cast(np.min(pdfProductData,0),tf.float32)\n",
    "    pmin = sess.run([pdfProductMin])\n",
    "    return pmin\n",
    "\n",
    "def initModel():\n",
    "    dataSet = initData()\n",
    "    dist = initDist(dataSet)\n",
    "    pdfProductSet = getPdfProductSet(dist,dataSet)\n",
    "    minPdf = getMinPdf(pdfProductSet)\n",
    "    model = {'dist':dist,'KPI':minPdf}\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initData done\n",
      "means\n",
      "[ 0.18839677  0.98783195  0.99686903  0.70659477]\n",
      "correlation\n",
      "[[ 1.         -0.01845233  0.01940105  0.21830939]\n",
      " [-0.01845233  1.          0.78289269  0.14058522]\n",
      " [ 0.01940105  0.78289269  1.          0.11831333]\n",
      " [ 0.21830939  0.14058522  0.11831333  1.        ]]\n",
      "cov\n",
      "[[  6.24744617e-03  -2.04965619e-05   1.54357337e-05   1.22090154e-03]\n",
      " [ -2.04965619e-05   1.97495387e-04   1.10746865e-04   1.39789679e-04]\n",
      " [  1.54357337e-05   1.10746865e-04   1.01321462e-04   8.42638629e-05]\n",
      " [  1.22090154e-03   1.39789679e-04   8.42638629e-05   5.00626584e-03]]\n",
      "initDist\n",
      "441.560904151\n",
      "441.560904151\n",
      "441.560904151\n",
      "[1.0186775e-19]\n"
     ]
    }
   ],
   "source": [
    "model = initModel()\n",
    "dist = model['dist']\n",
    "minP = model['KPI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
